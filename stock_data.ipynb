{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import date\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloding the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all stock\n",
    "list_of_stocks = [\"SPCE\", \n",
    "\"CPRX\", \n",
    "\"BABA\", \n",
    "\"AMZN\", \n",
    "\"SNE\", \n",
    "\"APHA\", \n",
    "\"TCEHY\", \n",
    "\"GOOGL\", \n",
    "\"MSFT\", \n",
    "\"NRZ\", \n",
    "\"PLUG\", \n",
    "\"PTON\", \n",
    "\"NKE\", \n",
    "\"ATVI\", \n",
    "\"PYPL\", \n",
    "\"FB\", \n",
    "\"GM\", \n",
    "\"KO\", \n",
    "\"V\", \n",
    "\"UBER\", \n",
    "\"MRNA\", \n",
    "\"ZNGA\", \n",
    "\"TXMD\", \n",
    "\"JNJ\", \n",
    "\"RCL\", \n",
    "\"NTDOY\", \n",
    "\"WMT\", \n",
    "\"DKNG\", \n",
    "\"JPM\", \n",
    "\"PENN\", \n",
    "\"SNAP\", \n",
    "\"GE\", \n",
    "\"ET\", \n",
    "\"NOK\", \n",
    "\"BP\", \n",
    "\"DAL\", \n",
    "\"LUV\", \n",
    "\"DIS\", \n",
    "\"SIRI\", \n",
    "\"NFLX\", \n",
    "\"LYFT\", \n",
    "\"NVDA\", \n",
    "\"BAC\", \n",
    "\"AAPL\", \n",
    "\"NIO\", \n",
    "\"WORK\", \n",
    "\"PFE\", \n",
    "\"SQ\", \n",
    "\"SBUX\", \n",
    "\"ZM\", \n",
    "\"KOS\", \n",
    "\"PLAY\", \n",
    "\"GILD\", \n",
    "\"UAL\", \n",
    "\"SAVE\", \n",
    "\"AMD\", \n",
    "\"BA\", \n",
    "\"NCLH\", \n",
    "\"HAL\", \n",
    "\"INTC\", \n",
    "\"T\", \n",
    "\"JBLU\", \n",
    "\"WFC\", \n",
    "\"MRO\", \n",
    "\"INO\", \n",
    "\"RKT\", \n",
    "\"TSLA\", \n",
    "\"CRON\", \n",
    "\"TWTR\", \n",
    "\"CGC\", \n",
    "\"BYND\", \n",
    "\"MGM\", \n",
    "\"AAL\", \n",
    "\"F\", \n",
    "\"ACB\", \n",
    "\"GPRO\", \n",
    "\"MFA\", \n",
    "\"TLRY\", \n",
    "\"CCL\", \n",
    "\"XOM\", \n",
    "\"HEXO\", \n",
    "\"FIT\", \n",
    "\"NKLA\", \n",
    "\"AMC\", \n",
    "\"WKHS\", \n",
    "\"VOO\", \n",
    "\"SPY\", \n",
    "\"GUSH\", \n",
    "\"IVR\", \n",
    "\"USO\", \n",
    "\"UCO\", \n",
    "\"PSEC\", \n",
    "\"FCEL\", \n",
    "\"SPHD\", \n",
    "\"PLTR\", \n",
    "\"IBIO\", \n",
    "\"SRNE\", \n",
    "\"KODK\", \n",
    "\"VTI\",\n",
    "\"HOME\",\n",
    "\"SOLO\",\n",
    "\"BLNK\",\n",
    "\"PLUG\",\n",
    "\"BLDP\"\n",
    "]\n",
    "\n",
    "ev_renewable = [\"SOLO\",\n",
    "\"BLNK\",\n",
    "\"PLUG\",\n",
    "\"BLDP\",\n",
    "\"FCEL\"\n",
    "]\n",
    "\n",
    "renewable = [\n",
    "    \"EOSE\",\n",
    "    \"BLDP\",\n",
    "    \"PLUG\",\n",
    "    \"BE\",\n",
    "    \"FCEL\",\n",
    "    \"SBE\"\n",
    "]\n",
    "\n",
    "top_performing = [\"XPEV\",\n",
    "\"CELH\",\n",
    "\"LI\",\n",
    "\"FPRX\",\n",
    "\"FOSL\",\n",
    "\"PDD\",\n",
    "\"FLGT\",\n",
    "\"GRWG\",\n",
    "\"ATRA\",\n",
    "\"NAK\",\n",
    "\"DSKE\",\n",
    "\"SVC\",\n",
    "\"PEYUF\",\n",
    "\"BEAM\",\n",
    "\"MPLN\",\n",
    "\"VRM\",\n",
    "\"ENR\",\n",
    "\"SFL\",\n",
    "\"CCMP\",\n",
    "\"GOCO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to extract two things from data:\n",
    "1. year-to-date change\n",
    "2. march 23 crash to date change\n",
    "3. Aug 31st tech stagnation to date change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_difference(date_1, date_2):\n",
    "    date_to_date = lambda date: ([date.split('-')[0], date.split('-')[1], date.split('-')[2]])\n",
    "    \n",
    "    day_1 = date_to_date(date_1)\n",
    "    day_2 = date_to_date(date_2)\n",
    "\n",
    "    date_diff = (date(int(day_2[0]), int(day_2[1]), int(day_2[2])) - date(int(day_1[0]), int(day_1[1]), int(day_1[2]))).days\n",
    "    return date_diff\n",
    "\n",
    "def trend_finder(date_1, date_2):\n",
    "    trend = ((data.loc[date_2][\"Close\"] - data.loc[date_1][\"Close\"]) / data.loc[date_1][\"Close\"]) * (100/date_difference(date_1, date_2))\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module gives back the performance over the past days_back days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_by_day_record(days_back, interval):\n",
    "    trends_dict = {}\n",
    "    \n",
    "    for i in range(days_back):\n",
    "        day_1 = (date.today()-datetime.timedelta(i+(2*interval))).strftime(\"%Y-%m-%d\")\n",
    "        day_2 = (date.today()-datetime.timedelta(i+interval)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        try:\n",
    "            day_1_to_day_2 = trend_finder(day_1, day_2)\n",
    "            day_name = 'date ' + str(i+1) + ' to date ' + str(i+2)\n",
    "            trends_dict[day_name] = day_1_to_day_2\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    trends_df = pd.DataFrame(trends_dict) \n",
    "    \n",
    "    trends_df['average'] = trends_df.mean(axis=1)\n",
    "    trends_df['standard deviation'] = trends_df.std(axis=1)\n",
    "    trends_df['normal average'] = trends_df['average'] / trends_df['standard deviation']  \n",
    "    \n",
    "    return (trends_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_beginning = '2020-01-02'\n",
    "\n",
    "crash = '2020-03-23'\n",
    "\n",
    "stagnation = '2020-08-31'\n",
    "\n",
    "election = '2020-11-03'\n",
    "\n",
    "today = (date.today()-datetime.timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "today = '2020-11-13'\n",
    "\n",
    "\n",
    "year_beginning_to_crash_trend = trend_finder(year_beginning, crash)\n",
    "crash_to_stagnation_trend = trend_finder(crash, stagnation)\n",
    "stagnation_to_election_trend = trend_finder(stagnation, election)\n",
    "election_to_date_trend = trend_finder(election, today)\n",
    "\n",
    "trends_dict = { 'year_beginning_to_crash_trend': year_beginning_to_crash_trend,\n",
    "               'crash_to_stagnation_trend': crash_to_stagnation_trend, \n",
    "         'stagnation_to_election_trend': stagnation_to_election_trend,\n",
    "        'election_to_date_trend': election_to_date_trend} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the current local date \n",
    "today = date.today() \n",
    "\n",
    "data = yf.download(renewable,'2020-01-01',today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  103 of 103 completed\n"
     ]
    }
   ],
   "source": [
    "# downloading data from Yahoo! Finance)\n",
    "data = yf.download(list_of_stocks,'2020-01-01', date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_by_day_record(df, count_back, interval, date = date.today()):\n",
    "    \n",
    "    # getting all active stock dates from the downloaded data\n",
    "    stock_active_dates = [str(date).split('T')[0] for date in list(df.index.values)]\n",
    "    \n",
    "    T = 1\n",
    "    \n",
    "    # finding the first valid date\n",
    "\n",
    "    while True:\n",
    "        start_date = (date-datetime.timedelta(T)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        if start_date in stock_active_dates: \n",
    "            start_date = date-datetime.timedelta(T)\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            T += 1\n",
    "    \n",
    "    # starting from start date and going back in time until we find enough valid dates\n",
    "            \n",
    "    valid_dates = [(date-datetime.timedelta(T)).strftime(\"%Y-%m-%d\")]    \n",
    "    \n",
    "    i = 1\n",
    "\n",
    "    while len(valid_dates) < count_back:\n",
    "        \n",
    "        # this day is closer to today\n",
    "        test_day = (start_date - datetime.timedelta(i*interval+1))\n",
    "\n",
    "        if test_day.strftime(\"%Y-%m-%d\") in stock_active_dates:\n",
    "            valid_dates.append(test_day.strftime(\"%Y-%m-%d\"))\n",
    "            \n",
    "        # fidning the closest day that works \n",
    "        else:\n",
    "            T = 1\n",
    "            \n",
    "            while True:\n",
    "                approx_date = (test_day - datetime.timedelta(T)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                if approx_date in stock_active_dates: \n",
    "                    valid_dates.append(approx_date)\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    T += 1\n",
    "                    \n",
    "        i += 1\n",
    "        \n",
    "    trends_dict = {}\n",
    "    for i in range(len(valid_dates)):\n",
    "        if i < len(valid_dates)-1:\n",
    "            date_1 = valid_dates[i]\n",
    "            date_2 = valid_dates[i+1]\n",
    "        \n",
    "        try:\n",
    "            trend = ((df.loc[date_2][\"Close\"] - df.loc[date_1][\"Close\"]) / df.loc[date_1][\"Close\"]) * (100/date_difference(date_1, date_2))\n",
    "\n",
    "            day_name = str(date_1) + '   ' + str(date_2)\n",
    "            trends_dict[day_name] = trend\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    trends_df = pd.DataFrame(trends_dict) \n",
    "\n",
    "    trends_df['average'] = trends_df.mean(axis=1)\n",
    "    trends_df['standard deviation'] = trends_df.std(axis=1)\n",
    "    trends_df['normal average'] = trends_df['average'] / (trends_df['standard deviation']**2)  \n",
    "\n",
    "    return (trends_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day_by_day_record(df, count_back, interval, start date*default at today*)\n",
    "\n",
    "trends_dataframe_90 = day_by_day_record(data, 90, 1, date = date.today()- datetime.timedelta(60))\n",
    "\n",
    "trends_dataframe_60 = day_by_day_record(data, 60, 1, date = date.today()- datetime.timedelta(30))\n",
    "\n",
    "trends_dataframe_30 = day_by_day_record(data, 30, 1)\n",
    "\n",
    "trends_dataframe_7 = day_by_day_record(data, 7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = trends_dataframe_90.sort_values(by=['average'], ascending=False)\n",
    "\n",
    "A = c[c['average'] > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = trends_dataframe_60.sort_values(by=['average'], ascending=False)\n",
    "\n",
    "B = c[c['average'] > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = trends_dataframe_30.sort_values(by=['average'], ascending=False)\n",
    "\n",
    "C = c[c['average'] > 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NIO', 'BABA', 'INTC', 'TCEHY', 'SNAP', 'NFLX', 'TSLA', 'SNE', 'SBUX',\n",
       "       'V', 'PLAY', 'JNJ', 'UCO', 'GILD', 'RCL', 'AMZN', 'KO', 'DIS', 'ATVI',\n",
       "       'SIRI', 'JPM', 'USO', 'IVR', 'NVDA', 'NOK', 'LUV', 'NCLH', 'SPY', 'VOO',\n",
       "       'GE', 'NTDOY', 'BAC', 'WFC', 'CCL', 'T', 'DAL', 'FIT', 'FB', 'VTI',\n",
       "       'SPHD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = trends_dataframe_7.sort_values(by=['average'], ascending=False)\n",
    "\n",
    "D = c[c['average'] > 0].index\n",
    "\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CCL',\n",
       " 'DAL',\n",
       " 'GE',\n",
       " 'JPM',\n",
       " 'KO',\n",
       " 'NCLH',\n",
       " 'NIO',\n",
       " 'NTDOY',\n",
       " 'PLAY',\n",
       " 'SBUX',\n",
       " 'SNAP',\n",
       " 'SNE',\n",
       " 'TCEHY',\n",
       " 'TSLA',\n",
       " 'VTI'}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = set.intersection(set(A),set(B),set(C), set(D))\n",
    "u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
